{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import normalize    \n",
    "from sklearn.preprocessing import LabelEncoder  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"clean1.data\") as f:\n",
    "    lines1 = f.readlines()\n",
    "    \n",
    "with open(\"clean2.data\")  as f:\n",
    "    lines2 = f.readlines()\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(\"MUSK-jf78,MUSK-jf67,MUSK-jf59,MUSK-jf58,MUSK-jf47,MUSK-jf46,MUSK-jf17,MUSK-j51,MUSK-j33,MUSK-f205,MUSK-f184,MUSK-f159,MUSK-f158,MUSK-f152,MUSK-344,MUSK-333,MUSK-331,MUSK-330,MUSK-323,MUSK-322,MUSK-321,MUSK-316,MUSK-315,MUSK-314,MUSK-311,MUSK-301,MUSK-293,MUSK-292,MUSK-285,MUSK-284,MUSK-273,MUSK-272,MUSK-256,MUSK-254,MUSK-246,MUSK-240,MUSK-238,MUSK-236,MUSK-228,MUSK-227,MUSK-224,MUSK-219,MUSK-213,MUSK-212,MUSK-211,MUSK-190,MUSK-188,NON-MUSK-jp13,NON-MUSK-jp10,NON-MUSK-j97,NON-MUSK-j96,NON-MUSK-j93,NON-MUSK-j90,NON-MUSK-j84,NON-MUSK-j83,NON-MUSK-j81,NON-MUSK-j148,NON-MUSK-j147,NON-MUSK-j146,NON-MUSK-j130,NON-MUSK-j129,NON-MUSK-j100,NON-MUSK-f209,NON-MUSK-f164,NON-MUSK-f161,NON-MUSK-f150,NON-MUSK-334,NON-MUSK-327,NON-MUSK-320,NON-MUSK-319,NON-MUSK-318,NON-MUSK-309,NON-MUSK-308,NON-MUSK-305,NON-MUSK-297,NON-MUSK-296,NON-MUSK-295,NON-MUSK-290,NON-MUSK-289,NON-MUSK-288,NON-MUSK-286,NON-MUSK-271,NON-MUSK-257,NON-MUSK-253,NON-MUSK-249,NON-MUSK-247,NON-MUSK-232,NON-MUSK-226,NON-MUSK-220,NON-MUSK-208,NON-MUSK-200,NON-MUSK-199,NON-MUSK-jp13,NON-MUSK-jp10,NON-MUSK-jf79,NON-MUSK-jf18,NON-MUSK-j97,NON-MUSK-j96,NON-MUSK-j90,NON-MUSK-j84,NON-MUSK-j83,NON-MUSK-j81,NON-MUSK-j148,NON-MUSK-j147,NON-MUSK-j146,NON-MUSK-j130,NON-MUSK-j129,NON-MUSK-j100,NON-MUSK-f209,NON-MUSK-f164,NON-MUSK-f161,NON-MUSK-f150,NON-MUSK-f146,NON-MUSK-362,NON-MUSK-361,NON-MUSK-360,NON-MUSK-358,NON-MUSK-338,NON-MUSK-334,NON-MUSK-332,NON-MUSK-328,NON-MUSK-327,NON-MUSK-326,NON-MUSK-320,NON-MUSK-319,NON-MUSK-318,NON-MUSK-309,NON-MUSK-308,NON-MUSK-305,NON-MUSK-297,NON-MUSK-296,NON-MUSK-295,NON-MUSK-290,NON-MUSK-289,NON-MUSK-288,NON-MUSK-286,NON-MUSK-271,NON-MUSK-270,NON-MUSK-253,NON-MUSK-252,NON-MUSK-251,NON-MUSK-249,NON-MUSK-244,NON-MUSK-233,NON-MUSK-232,NON-MUSK-226,NON-MUSK-220,NON-MUSK-216,NON-MUSK-210,NON-MUSK-208,NON-MUSK-207,NON-MUSK-200,NON-MUSK-199,NON-MUSK-197,NON-MUSK-192,MUSK-jf78,MUSK-jf67,MUSK-jf66,MUSK-jf59,MUSK-jf58,MUSK-jf47,MUSK-jf46,MUSK-jf17,MUSK-jf15,MUSK-j51,MUSK-j33,MUSK-f158,MUSK-f152,MUSK-344,MUSK-333,MUSK-331,MUSK-330,MUSK-323,MUSK-322,MUSK-321,MUSK-314,MUSK-306,MUSK-300,MUSK-294,MUSK-287,MUSK-284,MUSK-273,MUSK-256,MUSK-240,MUSK-238,MUSK-228,MUSK-224,MUSK-219,MUSK-217,MUSK-215,MUSK-214,MUSK-213,MUSK-212,MUSK-211\".split(\",\"))\n",
    "# Use only col 0 + cols 2 (inclusive) -> 169 (exclusive)\n",
    "data =np.loadtxt('clean1.data', dtype=int, delimiter=',',usecols=[0] + list(range(2,169)), \\\n",
    "                 converters={0: lambda s: le.transform([str(s)])[0],\\\n",
    "                             168: lambda s: int(float(s))}, encoding='utf-8')\n",
    "data =np.concatenate((data, np.loadtxt('clean2.data', dtype=int, \\\n",
    "                                       delimiter=',',usecols=[0] + list(range(2,169)), \\\n",
    "                                       converters={0: lambda s: le.transform([str(s)])[0],\\\n",
    "                                                   168: lambda s: int(float(s))}, encoding='utf-8')\n",
    "), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7074, 168)\n"
     ]
    }
   ],
   "source": [
    "molecule_bags = np.expand_dims(data[:,0], 1)\n",
    "molecule_labels = np.expand_dims(data[:,-1], 1)\n",
    "normed_data = np.concatenate((molecule_bags,normalize(data[:,1:-1], norm='l2', axis=0)), axis=1) \n",
    "normed_data = np.concatenate((normed_data, molecule_labels), axis=1)\n",
    "print(normed_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "tf.enable_eager_execution()\n",
    "tfe = tf.contrib.eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tfe.Variable(np.random.uniform(size=[166,]), name='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost before\n",
      "tf.Tensor(3.753991038825871, shape=(), dtype=float64)\n",
      "\n",
      "epoch 0\n",
      "cost tf.Tensor(3.669808336691609, shape=(), dtype=float64)\n",
      "cost tf.Tensor(3.6284268707778993, shape=(), dtype=float64)\n",
      "cost tf.Tensor(3.5875225373256088, shape=(), dtype=float64)\n",
      "cost tf.Tensor(3.5470974890494507, shape=(), dtype=float64)\n",
      "cost tf.Tensor(3.507153805566373, shape=(), dtype=float64)\n",
      "cost tf.Tensor(3.4676927263734196, shape=(), dtype=float64)\n",
      "cost tf.Tensor(3.4287146695811135, shape=(), dtype=float64)\n",
      "cost tf.Tensor(3.390221349863435, shape=(), dtype=float64)\n",
      "cost tf.Tensor(3.352213683316429, shape=(), dtype=float64)\n",
      "cost tf.Tensor(3.3146928768347186, shape=(), dtype=float64)\n",
      "cost tf.Tensor(3.277658527641117, shape=(), dtype=float64)\n",
      "cost tf.Tensor(3.241109039547112, shape=(), dtype=float64)\n",
      "cost tf.Tensor(3.205043855237462, shape=(), dtype=float64)\n",
      "cost tf.Tensor(3.1694614628832096, shape=(), dtype=float64)\n",
      "cost tf.Tensor(3.1343591584509665, shape=(), dtype=float64)\n",
      "cost tf.Tensor(3.099733981012563, shape=(), dtype=float64)\n",
      "cost tf.Tensor(3.065583993944161, shape=(), dtype=float64)\n",
      "cost tf.Tensor(3.031906494065089, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.998697903652132, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.9659559069271197, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.9336765302408505, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.9018557887165284, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.8704890176413107, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.8395721756415235, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.8090998979974082, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.779067569129453, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.7494709057905538, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.720304905327276, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.6915645423004175, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.6632443924542653, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.6353394210240206, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.607843136099585, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.5807510572901933, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.5540567438181347, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.5277541793405134, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.5018370725502774, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.476300346695575, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.4511387876451027, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.4263476199370766, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.4019205112843216, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.3778515846675896, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.354135215611099, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.3307664175058593, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.3077398735992376, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.2850500535513514, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.2626909061266063, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.2406569652757065, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.218942704781811, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.197542870322861, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.1764517848462024, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.1556640169034456, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.1351738772150397, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.1149756245698637, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.0950644530125615, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.0754350036516787, shape=(), dtype=float64)\n",
      "epoch 1\n",
      "cost tf.Tensor(2.0369932916550155, shape=(), dtype=float64)\n",
      "cost tf.Tensor(2.018172086892123, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.999611658030545, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.9813076180114944, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.9632557246480251, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.945451438486701, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.9278905496099734, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.910568848249156, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.8934824012342233, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.8766277471283404, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.8600010575793993, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.8435986988721977, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.8274165118161436, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.8114503637124781, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.7956964850842998, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.7801516130148896, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.7648115760598322, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.7496726878277964, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.7347318053824519, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.7199857457387089, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.7054316589911604, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.691066033535954, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.6768856747004568, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.6628873116181613, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.649067750777858, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.635423829308831, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.621952527799659, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.6086508422493968, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.595515963803017, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.582545026781003, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.569735553173806, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.5570849918755216, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.5445906896798562, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.5322499803254679, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.5200606403192671, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.5080196414553717, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.4961247671350508, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.4843735782974892, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.472763977642401, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.4612936163454449, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.4499598159474456, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.4387607342916549, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.4276942735016522, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.4167584946670062, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.4059510889599904, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.3952698665414809, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.384712803446237, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.3742784005859903, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.3639645772340487, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.353769175941866, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.3436902283187087, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.3337260540065698, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.3238747497616876, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.31413442185951, shape=(), dtype=float64)\n",
      "cost tf.Tensor(1.304503442966674, shape=(), dtype=float64)\n",
      "cost after\n",
      "tf.Tensor(0.18251589811149938, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "def prob_x_given_Bi_minus(Bi, x):\n",
    "    exps = tf.exp(-tf.norm(Bi-x, ord=2, keepdims=True, axis=1)) # Axis is 1 for the norm \\\n",
    "    return tf.reduce_prod(tf.map_fn(lambda s:1-s, exps), axis=0, \\\n",
    "                          keepdims=True, name='prob_x_given_Bi_minus')\n",
    "\n",
    "def get_bags(minibatch, bag_idx, x):\n",
    "    bag_id_labels = minibatch[:,0]\n",
    "    rows = tf.gather(minibatch,tf.where(tf.equal(bag_id_labels, bag_id)))\n",
    "    return prob_x_given_Bi_minus(rows, x)\n",
    "\n",
    "def compute_cost(minibatch, x):\n",
    "    joint_prob = tf.constant(0, dtype=tf.float64) # Overall probability we're argmaxing over\n",
    "    bag_ids = tf.unique(minibatch[:,0])[0]\n",
    "    for i in range(bag_ids.shape[0]):\n",
    "        bag_id = bag_ids[i]\n",
    "        bag_id_labels = minibatch[:,0]\n",
    "        where = tf.where(tf.equal(bag_id_labels, bag_id))\n",
    "        rows = tf.gather(minibatch,tf.reshape(where, [where.shape[0],]))\n",
    "        Bi, Bi_label = rows[:,1:-1], rows[0,-1]\n",
    "        prob=prob_x_given_Bi_minus(Bi, x)[0][0]\n",
    "        cons = tf.constant(1*10**-8, dtype=tf.float64)\n",
    "        inner_sum = tf.add(prob, cons)\n",
    "        log_result = tf.log(inner_sum)\n",
    "        joint_prob = tf.add(joint_prob, log_result)\n",
    "    return -joint_prob\n",
    "\n",
    "# def get_minibatches(dataset):\n",
    "#     \"\"\" Shuffle and return minibatches for dataset.\n",
    "#     \"\"\"\n",
    "\n",
    "# x=tfe.Variable(np.random.uniform(size=[166,]), name='x', dtype=tf.float64)\n",
    "# f_grad = tfe.gradients_function(lambda s: compute_cost(tf.constant(normed_data[:10], dtype=tf.float64), s), params=['s'])\n",
    "# print(\"F grad \" + str(f_grad(x) + '\\n'))\n",
    "# print(\"\\nGradient \" + str(f_grad(x)))\n",
    "# f_grad = tfe.gradients_function(compute_cost, params=['x'])\n",
    "\n",
    "x=tfe.Variable(np.random.uniform(size=[166,]), name='x', dtype=tf.float64)\n",
    "# print(\"x before\" + str(x))\n",
    "print(\"cost before\")\n",
    "print(str(compute_cost(tf.constant(normed_data, dtype=tf.float64), x)) + '\\n')\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "#     minibatch_q = tf.RandomShuffleQueue(normed_data.shape[0], 0, tf.float64, shapes=[168,])\n",
    "#     minibatch_q.enqueue_many(normed_data[:312])\n",
    "#     for i in range(3):\n",
    "#         minibatch = minibatch_q.dequeue_many(128)\n",
    "    shuffled = tf.random_shuffle(normed_data)\n",
    "    print(\"epoch \" + str(epoch))\n",
    "    minibatch_size = 128\n",
    "    for i in range(shuffled.shape[0]//minibatch_size + 1):\n",
    "        mb_start = i\n",
    "        mb_end = i + minibatch_size if (i+minibatch_size) <= len(normed_data) else len(normed_data)\n",
    "        optimizer.minimize(lambda: compute_cost(tf.constant(shuffled[mb_start:mb_end], dtype=tf.float64), x), var_list=[x])\n",
    "        if i % 100:\n",
    "            print(\"cost \", end=\"\")\n",
    "            print(compute_cost(tf.constant(normed_data, dtype=tf.float64), x))\n",
    "print(\"cost after\")\n",
    "print(compute_cost(tf.constant(normed_data, dtype=tf.float64), x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost after\n",
      "tf.Tensor(1.304503442966674, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(\"cost after\")\n",
    "print(compute_cost(tf.constant(normed_data, dtype=tf.float64), x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def compute_cost(x):\n",
    "#     return x*5\n",
    "# def train(model, optimizer, dataset, step_counter, log_interval=None):\n",
    "#     \"\"\"Trains model on `dataset` using `optimizer`.\"\"\"\n",
    "\n",
    "#     start = time.time()\n",
    "#     for (batch, (images, labels)) in enumerate(dataset):\n",
    "#     with tf.contrib.summary.record_summaries_every_n_global_steps(\n",
    "#         10, global_step=step_counter):\n",
    "#       # Record the operations used to compute the loss given the input,\n",
    "#       # so that the gradient of the loss with respect to the variables\n",
    "#       # can be computed.\n",
    "#         with tf.GradientTape() as tape:\n",
    "#             logits = model(images, training=True)\n",
    "#             loss_value = loss(logits, labels)\n",
    "#             tf.contrib.summary.scalar('loss', loss_value)\n",
    "#             tf.contrib.summary.scalar('accuracy', compute_accuracy(logits, labels))\n",
    "#             grads = tape.gradient(loss_value, model.variables)\n",
    "#             optimizer.apply_gradients(\n",
    "#               zip(grads, model.variables), global_step=step_counter)\n",
    "#             if log_interval and batch % log_interval == 0:\n",
    "#                 rate = log_interval / (time.time() - start)\n",
    "#                 print('Step #%d\\tLoss: %.6f (%d steps/sec)' % (batch, loss_value, rate))\n",
    "#                 start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
