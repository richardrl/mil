{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open(\"clean1.data\") as f:\n",
    "    lines1 = f.readlines()\n",
    "    \n",
    "with open(\"clean2.data\")  as f:\n",
    "    lines2 = f.readlines()\n",
    "    \n",
    "# Use only cols 2 (inclusive) -> 169 (exclusive) because 1st col is name and 2nd col is conformation\n",
    "data =np.loadtxt('clean1.data', dtype=int, delimiter=',',usecols=list(range(2,169)), converters={168: lambda s: int(float(s))})\n",
    "data =np.concatenate((data, np.loadtxt('clean2.data', dtype=int, delimiter=',',usecols=list(range(2,169)), converters={168: lambda s: int(float(s))})\n",
    "), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 167)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[:5,]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richard/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_x_given_Bi_minus(Bi, x):\n",
    "    try:\n",
    "        assert x.shape == (166, 1)\n",
    "        assert Bi.shape == (166, 1)\n",
    "    except AssertionError as e:\n",
    "        print(e)\n",
    "        print(\"x.shape \" + str(x.shape))\n",
    "        print(\"Bi.shape \" + str(Bi.shape))\n",
    "    prob_x_Bi_vec = tf.map_fn(lambda s:1-s, tf.exp(-tf.norm(Bi-x, ord=2, keepdims=True)))\n",
    "    return tf.reduce_prod(prob_x_Bi_vec, axis=0, keepdims=True, name='prob_x_given_Bi_minus')\n",
    "\n",
    "# Remember to normalize inputs...\n",
    "def create_placeholders():\n",
    "    I = tf.placeholder(tf.int32, [None, 166], name=\"I\")\n",
    "    return I\n",
    "\n",
    "def compute_cost(I, x, sess): # TODO: Set I. Not used yet for mini-batch.\n",
    "    joint_prob = 0 # Overall probability we're argmaxing over\n",
    "    try:\n",
    "        assert I.shape == (None, 166, 1)\n",
    "        assert x.shape == (166, 1)\n",
    "    except AssertionError as e:\n",
    "        print(e)\n",
    "        print(\"I.shape \" + str(I.shape))\n",
    "        print(\"x.shape \" + str(x.shape))\n",
    "    for idx in range(data.shape[0]): # Iterate over bags\n",
    "        Bi, Bi_label = np.expand_dims(data[idx][:-1], 1), data[idx][-1]\n",
    "        print(\"Bi -x \" + str(sess.run(Bi-x)))\n",
    "        prob=prob_x_given_Bi_minus(Bi, x)\n",
    "#         joint_prob *= prob if not Bi_label else 1-prob\n",
    "        joint_prob += tf.log(prob)\n",
    "        print(\"logged \" + str(sess.run(joint_prob)))\n",
    "    return -joint_prob\n",
    "\n",
    "tf.reset_default_graph()\n",
    "I = create_placeholders() # TODO: Mini-batch input data.\n",
    "x = tf.get_variable(\"x\", [166, 1], initializer=tf.contrib.layers.xavier_initializer())\\\n",
    "# x = tf.get_variable(\"x\", [166, 1], initializer=tf.constant_initializer(data[0][:-1]))\\\n",
    "init = tf.global_variables_initializer()\n",
    "#     Initialize x parameter, which is the true concept we're trying to learn.\n",
    "# cost = compute_cost(data, x, sess)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "#     optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    # Initialize all the variables\n",
    "    sess.run(init)\n",
    "    print(sess.run(compute_cost(data[:,-1], \\\n",
    "                                tf.cast(np.expand_dims(data[0][:-1], 1), tf.float32), sess)))\n",
    "#     while True:\n",
    "#         intermediate_cost = sess.run([optimizer, cost])\n",
    "#         print(intermediate_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
